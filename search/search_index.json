{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CS202 - Computer Security - Lab 4 Adversarial Learning - 24 Fall","text":""},{"location":"#intro","title":"Intro","text":"<p>In this Lab, we would learn how to generate adversarial examples to attack machine learning models. More specifically, we will learn how to generate a set of adversarial images to deceive a CNN deep learning model to make them classify incorrecly.</p>"},{"location":"#prerequisite","title":"Prerequisite","text":"<p>Even though it's not necessary, I would suggest you having a machine with nvidia GPU CUDA support, which can accelerate predicting speed. If you don't have one, you can use Google Colab, which provides nvidia T4 for free. </p> <p>We will use learning framework <code>pytorch</code> and its <code>torchvision</code> library. About how to install them locally, referring this link. Install other necessary libraries. </p> <p>In addition to this, you still need download two files:</p> <ol> <li>Testset (testset.pt), which includes 100 images and their corresponding correct labels ((input_imgs, labels)). Each image is a tensor with shape 3\\times 32 \\times 32 (32 is the width and height of the image, and each pixel has 3 channels-red, green and blue). Each label is a single integer, which is the label. You need eventually made some minor perturbations to these images.</li> <li>ResNet Network (resnet.model), which is a classification neural network. It receives an image tensor and will generate an output with size <code>1000</code>. Each term in this torch indicates the probability that this image predicted by this model is the corresponsing labels. </li> </ol>"},{"location":"#algorithms","title":"Algorithms","text":"<p>We will introduce two adversarial training algorithms-fast gradient sign method (FGSM) and projected gradient descent (PGD). You are required to learn FGSM by yourself and generate the adversarial samples using it. PGD is optional and worth 2 bonus points. </p>"},{"location":"#fast-gradient-sign-method-10-pts","title":"Fast Gradient Sign Method (10 pts)","text":"<p>Pytorch provides the tutorial about this algorithm in detail. Just follow the instruction</p> <p>Generally, your code will contain following parts:</p> <ol> <li>Load provided ResNet model and data set. </li> <li>FGSM algorithm, which receives the model, input images, desirable labels and your choice of \\epsilon. Then return the adversarial pictures. </li> <li>Store the results for all 100 pictures and save them using <code>torch.save()</code></li> </ol> <p>Tips:</p> <p>The models and data set we provide is definitely SAFE, which means there is no executable code inside it. If you have concern, you can load them using <code>torch.load(weights_only=True)</code>. However, you need to add a lot of classes into <code>safe_globals</code> to load <code>ResNet</code> as it depends on a lot of classes. </p> <pre><code># Choose your device\ndevice = device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n# Load model\nmodel = torch.load(RESNET_MODEL_FILE, map_location=device)\n# Load dataset, set the map_location by your preference\ntestset = torch.load(TESTSET_FILE, weights_only=True)\n</code></pre> <p>Then you can use <code>torch.utils.data.DataLoader</code> to iterate over the dataset or just simply use <code>for</code> loop in python.</p> <p>You can use <code>pred_result = model(input_imgs)</code> to get the prediction result. </p>"},{"location":"#projected-gradient-descent-2-pts","title":"Projected Gradient Descent (2 pts)","text":"<p>You can learn the basic idea and principle from link.</p> <p>It's quite similar to FSGM, just in an iterative way. </p>"},{"location":"#submission","title":"Submission","text":"<p>You need to store all your adversarial samples into a list. Therefore, the finally submitted object should be <code>List[torch.tensor]</code> with \\text{length}=100, containing 100 adversarial images (the order should keep the same as the <code>testset</code>). Each tensor has the size of 3\\times 32\\times 32. Persist this list using <code>torch.save(adv_imgs, SAVE_FILE)</code>. </p> <p>Submit your file at SUBMISSION SITE. Your result would be AUTO-GRADED. Therefore, if you submit an incorrect file, you would receive low or zero grades. Double check your file before submitting and you can also write your self-check script to test your result. </p>"},{"location":"#grade-policy","title":"Grade Policy","text":"<p>Our test meets several guidelines:</p> <ol> <li>Less \\epsilon, higher grade. If you make less perturbation to the original image, you would receive a higher grade. If you increase your \\epsilon, your modification will then be easier to see. Your grade will drop exponentially with \\epsilon.</li> <li>Higher predicted difference, higher grade. If you acheive a higher mis-prediction rate on your adversarial samples, you would receive a higher grade. Your grade will increase linearly with the mis-prediction rate.</li> </ol> <p>Specifically, we would calculate three values for your ddversarial sampls:</p> <ol> <li>\\epsilon, which is the average difference between your submitted samples and original images (unit in pixel). In FGSM, this \\epsilon shoud be the same as your <code>eps</code>. In PGD, \\epsilon should be lower than <code>eps</code> you set in the algorithm as <code>eps</code> is the upperbound. </li> <li><code>tp1-accuracy-diff</code>: </li> <li>Top-1 accuracy is a metric used to evaluate the performance of a model. Given an image, the model outputs the probabilities for 1,000 labels. The label with the highest probability is referred to as the top-1 prediction. If this prediction matches the actual label, it is considered a True Positive. Using this, we can calculate the accuracy as \\text{tp1-acc} = \\frac{TP}{100}.</li> <li>We will calcualate the top-1 accuracy for both original dataset and your dataset and use |\\text{tp1-accuray-original} - \\text{tp1-accuracy-yours}| as <code>tp1_accuracy_diff</code>. A higher Top-1 accuracy difference means that your adversarial examples make it more difficult for the model to produce correct predictions, indicating that your adversarial learning algorithm is more successful.</li> <li><code>tp5-accuracy-diff</code>:</li> <li>Top-1 accuracy is essentially the same as accuracy. It's somehow too strict. You can turn out picking the most 5 highest prediction values from the probability instead of the highest one, and if any one of them matches the desirable label, we count them as a true positive, we can get Top-5 accuracy. </li> <li>We would also calculate the Top-5 accuracy difference for our grading. </li> </ol> <p>We will use following formula to calculate your grades:</p> <p>For FGSM, you will get the score according the maximum grade you get. </p>  \\text{TP1 Score} = 0.33 + 33\\times \\text{tp1-accuracy-diff} - e^{33\\times eps}\\\\ \\text{TP5 Score} = 66\\times \\text{tp5-accuracy-diff} - e^{33\\times eps}\\\\ \\text{Final Score} = \\text{min}(\\text{max}(\\text{max}(\\text{TP1 Score}, \\text{TP5 Score}), 0), 10)  <p>For PGD, you will get the score according to the minimum grade you get.</p>  \\text{TP1 Score} = 26\\times \\text{tp1-accuracy-diff} - e^{66\\times eps}\\\\ \\text{TP5 Score} = 46\\times \\text{tp5-accuracy-diff} - e^{66\\times eps}\\\\ \\text{Final Score} = 0.2\\times \\text{min}(\\text{max}(\\text{min}(\\text{TP1 Score}, \\text{TP5 Score}), 0), 10)  <p>PGD algorithm is more powerful and you can see it's more strict to \\epsilon. </p> <p>You can submit for FGSM for 10 TIMES amd 3 TIMES for PGD. Test by yourself before submitting.</p>"},{"location":"#questions","title":"Questions","text":"<p>Contacting me via email if you have any question. Attach your email, name and corresponding submission id. </p> <p>BONUS: Because this is a security course and you have learned about web security. If you can find any vulnerabilty in the submission website (this tutorial is a purely static website), we can give you some bonus for the lab :). </p> <p>Good luck, have fun!</p>"}]}